{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa9b5fff-72d6-4ca3-a4f4-6d0b7a73fbd7",
   "metadata": {},
   "source": [
    "# NLP Processing With SpaCy\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ed2846-5e73-4d30-89d3-2df5e8a9ce0c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Contents\n",
    "---\n",
    "- [Data Retrieval](#Data-Retrieval)\n",
    "- [SpaCy Processing](#SpaCy-Processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e439cdc-c8a9-4e8e-b178-95e0edbc770d",
   "metadata": {},
   "source": [
    "### Data Retrieval\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482adaa2-3d3e-42ba-9684-60efc4e1435e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Library Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "339b2b5c-8e79-4888-8964-0f69104364ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbfc33e-db37-45de-83e7-e4e5e583c484",
   "metadata": {},
   "source": [
    "**Read in cleaned_corpus.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "09aab4e8-671e-4b53-9cff-01090267eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_corpus = pd.read_csv('./data/cleaned_corpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "af8184bd-6fc9-4746-ae32-8874698284a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Traveling Journal of r/fountainpens (Appro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Sometimes, we just need this simple reminder ðŸ¤—</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I must confess I was wrong about Kaweco I've b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Why are cheap fountain pens so much better? Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Literally classic design Beautiful stripes and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit                                               text\n",
       "0          1  The Traveling Journal of r/fountainpens (Appro...\n",
       "1          1   Sometimes, we just need this simple reminder ðŸ¤—  \n",
       "2          1  I must confess I was wrong about Kaweco I've b...\n",
       "3          1  Why are cheap fountain pens so much better? Th...\n",
       "4          1  Literally classic design Beautiful stripes and..."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fdad68-5b86-4df6-95d9-71bb8693e552",
   "metadata": {},
   "source": [
    "### SpaCy Processing\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d7713580-8931-408c-bf0e-2583735234e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a7b450c4-feb9-40c4-8187-760241bf0fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the medium size pipeline\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9cc182-5ea7-48f1-9851-ebab3339e889",
   "metadata": {},
   "source": [
    "**Function that allows SpaCy to process text data so that it can be ran through an apply method for the 'text' column of the 'cleaned_corpus' dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d4782c2b-e768-4e2a-8279-1398119fa815",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function created using SpaCy lesson, references are https://spacy.io/api/token, https://realpython.com/natural-language-processing-spacy-python/#lemmatization, and ChatGPT for stucture help.  Hank reminded me that .apply will apply a function to a datafram column.\n",
    "\n",
    "def spacy_processor(text):\n",
    "    \n",
    "    #Put the data into spaCy model\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Create a tokens list with only alpha characters and leaving out any that are only one letter - which I saw during initial tests\n",
    "    tokens = [token.lemma_.lower().strip() for token in doc if token.is_alpha and not token.is_stop and len(token.text) > 1]\n",
    "\n",
    "    #Put the processed text back together\n",
    "    processed_text = ' '.join(tokens)\n",
    "\n",
    "    #return processed text to dataframe\n",
    "    return processed_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "421ccd54-8c5c-4398-aa6f-092ebe6bda1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the text column of the cleaned_corpus dataframe\n",
    "cleaned_corpus['processed_text'] = cleaned_corpus['text'].apply(spacy_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "885427c5-b9c6-4ae6-9a96-fb053d1a18d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Traveling Journal of r/fountainpens (Appro...</td>\n",
       "      <td>traveling journal fountainpens approve moderat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Sometimes, we just need this simple reminder ðŸ¤—</td>\n",
       "      <td>need simple reminder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I must confess I was wrong about Kaweco I've b...</td>\n",
       "      <td>confess wrong kaweco hobby decade especially l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Why are cheap fountain pens so much better? Th...</td>\n",
       "      <td>cheap fountain pen well cheap pen zero problem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Literally classic design Beautiful stripes and...</td>\n",
       "      <td>literally classic design beautiful stripe engr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit                                               text  \\\n",
       "0          1  The Traveling Journal of r/fountainpens (Appro...   \n",
       "1          1   Sometimes, we just need this simple reminder ðŸ¤—     \n",
       "2          1  I must confess I was wrong about Kaweco I've b...   \n",
       "3          1  Why are cheap fountain pens so much better? Th...   \n",
       "4          1  Literally classic design Beautiful stripes and...   \n",
       "\n",
       "                                      processed_text  \n",
       "0  traveling journal fountainpens approve moderat...  \n",
       "1                               need simple reminder  \n",
       "2  confess wrong kaweco hobby decade especially l...  \n",
       "3  cheap fountain pen well cheap pen zero problem...  \n",
       "4  literally classic design beautiful stripe engr...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking out how it looks\n",
    "cleaned_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6c924731-4aa7-473c-860f-dd9e62477fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'traveling journal fountainpens approve moderator greeting fountain pen family see original post propose pass journal new project read thrilled announce moderate team generously agree support assist ambitious undertaking great deal interested party room like project read outline instruction extremely excited move look forward amazing entry traveling journal fountainpens sub compose unique individual view experience talent creativity unite shared passion remarkable writing tool fountain pen capture uniqueness single tome sharing preservation plan straightfoward physical journal send member person add new entry typical journal diary type write entry lyric favorite meaningful song movie famous quote artwork feel like contribute periodically send archiving send member continue chain journal fill restriction add detail procedure take project fairly simple join sign submit info google form create mailing email address reddit username create free account require highly recommend save subscribe thread public update personal info share purpose project additionally member address info previous contributor help maintain privacy security asana account asana project management tool allow track journal communicate contributor serve way effectively efficiently move maintain privacy possible good sized list contributor sign organize address journal stay country region long possible help save shipping cost rule sign project dedicate mind timely nature project reasonably prompt entry forwarding journal understand small financial requirement form postage responsibility send internationally cost minimal familiar shipping price entry shall defamatory disparaging overtly vulgar harmful hurtful overtly vulgar mean use cursing refrain nude artwork thing nature basically add consider trashy romance novel fine art nude thing porn completely deface alter person entry ideally great addition entry list moderator agree violation rule repercussion contributor membership sub journal look feel suit project torcello firenze papuro open suggestion completely different journal requirement decent reasonable size cm large sheet total page unlined especially purposeful artwork leather fux leather cover aesthetic reason mention journal periodically send archive case unthinkable happen journal get lose damage ultimate goal create ebook sub member able project moderator support question concern let know hope move soon wait result want thank pandavictus help way edit wow signup look like able forward soon objection soon move forward purchase journal list thank support little idea'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking out the first entry in the processed_text column\n",
    "cleaned_corpus['processed_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bf9d7f5f-f25a-44c8-9f7b-8102e0cc0b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK to drop the text column\n",
    "cleaned_corpus.drop(columns = 'text', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "14b9aff8-5088-484b-9be9-f96bb7086a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>traveling journal fountainpens approve moderat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>need simple reminder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>confess wrong kaweco hobby decade especially l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>cheap fountain pen well cheap pen zero problem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>literally classic design beautiful stripe engr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit                                     processed_text\n",
       "0          1  traveling journal fountainpens approve moderat...\n",
       "1          1                               need simple reminder\n",
       "2          1  confess wrong kaweco hobby decade especially l...\n",
       "3          1  cheap fountain pen well cheap pen zero problem...\n",
       "4          1  literally classic design beautiful stripe engr..."
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d904bc3-cfa7-4c09-9e0a-554257a6108a",
   "metadata": {},
   "source": [
    "I noticed when modeling that after reading in the data, there were four NaNs.  I realized that four of the rows in the dataset at thos point only had ''.  While not considered a NaN, there is no data here.  I will drop these columns.  There were either just emojis for text or stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bdd16e22-8939-4df3-9971-5b4c31a0a34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2604</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2661</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      subreddit processed_text\n",
       "749           1               \n",
       "1140          0               \n",
       "2604          1               \n",
       "2661          0               "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_corpus[cleaned_corpus['processed_text'] == '']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bda3cf93-63be-4e82-95a0-43b56a89ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_corpus.drop([749,1140,2604,2661], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8518ab11-bba0-4a81-bad9-6b7ed9607139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2796, 2)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_corpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3978f377-7ef5-46c2-aa18-5343d377063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_corpus.to_csv('./data/text_processed_corpus.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
